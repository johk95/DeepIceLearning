{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jkutils, updown_network\n",
    "import os, sys, math\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "#from scipy.misc import imsave\n",
    "import time\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import math\n",
    "import shelve\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def figsize(scale,scale_height=None):\n",
    "    fig_width_pt = 360.0                          # Get this from LaTeX using \\the\\textwidth\n",
    "    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n",
    "    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n",
    "    if scale_height == None or type(scale_height) not in (int,float):\n",
    "        scale_height = golden_mean\n",
    "    height_scale = scale_height\n",
    "    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n",
    "    fig_height = fig_width*height_scale              # height in inches\n",
    "    fig_size = [fig_width,fig_height]\n",
    "    return fig_size\n",
    "\n",
    "def savefig(filename):\n",
    "    plt.savefig(os.path.join('../plots/','{}.pgf'.format(filename)))\n",
    "    plt.savefig(os.path.join('../plots/','{}_pdf.pdf'.format(filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpl.use('pgf')\n",
    "\n",
    "pgf_with_latex = {                      # setup matplotlib to use latex for output\n",
    "    \"pgf.texsystem\": \"pdflatex\",        # change this if using xetex or lautex\n",
    "    \"text.usetex\": True,                # use LaTeX to write all text\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [],                   # blank entries should cause plots to inherit fonts from the document\n",
    "    \"font.sans-serif\": [],\n",
    "    \"font.monospace\": [],\n",
    "    \"axes.labelsize\": 10,               # LaTeX default is 10pt font.\n",
    "    \"font.size\": 10,\n",
    "    \"legend.fontsize\": 8,               # Make the legend/label fonts a little smaller\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,\n",
    "    \"figure.figsize\": figsize(0.9),     # default fig size of 0.9 textwidth\n",
    "    \"pgf.preamble\": [\n",
    "        r\"\\usepackage[utf8x]{inputenc}\",    # use utf8 fonts becasue your computer can handle it :)\n",
    "        r\"\\usepackage[T1]{fontenc}\",        # plots will be generated using this preamble\n",
    "        ]\n",
    "    }\n",
    "mpl.rcParams.update(pgf_with_latex)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/cvmfs/icecube.opensciencegrid.org/py2-v2/RHEL_6_x86_64/lib/python2.7/site-packages/matplotlib/pyplot.pyc'>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(mpl)\n",
    "mpl.use('pgf')\n",
    "\n",
    "pgf_with_latex = {                      # setup matplotlib to use latex for output\n",
    "    \"pgf.texsystem\": \"pdflatex\",        # change this if using xetex or lautex\n",
    "    \"text.usetex\": True,                # use LaTeX to write all text\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [],                   # blank entries should cause plots to inherit fonts from the document\n",
    "    \"font.sans-serif\": [],\n",
    "    \"font.monospace\": [],\n",
    "    \"axes.labelsize\": 10,               # LaTeX default is 10pt font.\n",
    "    \"font.size\": 10,\n",
    "    \"legend.fontsize\": 8,               # Make the legend/label fonts a little smaller\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,\n",
    "    \"figure.figsize\": figsize(0.9),     # default fig size of 0.9 textwidth\n",
    "    \"pgf.preamble\": [\n",
    "        r\"\\usepackage[utf8x]{inputenc}\",    # use utf8 fonts becasue your computer can handle it :)\n",
    "        r\"\\usepackage[T1]{fontenc}\",        # plots will be generated using this preamble\n",
    "        ]\n",
    "    }\n",
    "mpl.rcParams.update(pgf_with_latex)\n",
    "\n",
    "reload(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#time\n",
    "today = '2017-08-24'\n",
    "project_name = 'time_h012_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for train_hist/2017-08-24/time_h012_v1\n",
      "found\n"
     ]
    }
   ],
   "source": [
    "file_location = '/data/user/jkager/NN_Reco/johannes/updownclassification_3/'\n",
    "data_location = '/data/user/jkager/NN_Reco/training_data_20x10x60/'\n",
    "test_results = 'test_results.npy'\n",
    "\n",
    "project_folder = 'train_hist/{}/{}'.format(today, project_name)\n",
    "print \"looking for\", project_folder\n",
    "if not os.path.exists(os.path.join(file_location,project_folder)):\n",
    "    print \"project not found. exiting...\"\n",
    "    sys.exit(-1)\n",
    "elif not os.path.exists(os.path.join(file_location, project_folder, test_results)):\n",
    "    print \"test results not found. exiting...\"\n",
    "    sys.exit(-1)\n",
    "print \"found\"\n",
    "shelf = shelve.open(os.path.join(file_location, project_folder, 'run_info.shlf'))\n",
    "input_files = shelf['Files'].split(':')\n",
    "if len(input_files) == 1: #this could be something like ['h01'] (inputformat)\n",
    "    #try to decode fileinput format\n",
    "    input_files = jkutils.get_filenames(input_files[0])\n",
    "    for f in input_files:\n",
    "        if not os.path.isfile(os.path.join(data_location, 'training_data/{}'.format(f))):\n",
    "            print \"file not found:\", f\n",
    "            print \"exiting script.\"\n",
    "            sys.exit(1)\n",
    "projectpath=os.path.join(file_location,project_folder)\n",
    "train_inds = shelf['Train_Inds'] \n",
    "valid_inds = shelf['Valid_Inds']\n",
    "test_inds = shelf['Test_Inds']\n",
    "inf_times_as = shelf['inf_times_as']\n",
    "norm = shelf['time_normalized'] if shelf.has_key('time_normalized') else False\n",
    "test_results = np.load(os.path.join(projectpath, test_results))\n",
    "input_data, out_data, file_len = jkutils.read_files(\n",
    "    input_files, \n",
    "    data_location, \n",
    "    using=shelf['using'])\n",
    "res, test_out, zenith_out = test_results[0,:], test_results[1,:], test_results[2,:] #network output (0 or 1), \n",
    "                                                                                    #desired output (0 or 1),\n",
    "                                                                                    #zenith (0 to pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Files': '11069_00000-00999.h5:11069_01000-01999.h5:11069_02000-02999.h5', 'inf_times_as': 1.0, 'Valid_Inds': [(124352, 165803), (125784, 167712), (125878, 167837)], 'Test_Inds': [(165803, 207253), (167712, 209639), (167837, 209796)], 'Project': 'time_h012_v1', 'Train_Inds': [(0, 124352), (0, 125784), (0, 125878)], 'arguments': \"['/mnt/lfs3/user/jkager/NN_Reco/johannes/updownclassification_3/condor_submit/../updown_network.py', '--project', 'time_h012_v1', '--continue', 'None', '--model=CNN_v1.cfg', '--input=h012', '--using=time', '--date', '2017-08-24']\", 'using': 'time'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=load_model(os.path.join(projectpath, 'final_network.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 9, 5, 28, 64)      3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 9, 5, 28, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 9, 5, 28, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 5, 3, 14, 64)      110656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 5, 3, 14, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5, 3, 14, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 13440)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13440)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               6881792   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 7,127,681\n",
      "Trainable params: 7,127,425\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml = model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filter(lambda f: 'conv' in f.name, model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize filters (see local file) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# visualization of image with gradient ascent (see local file) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# filter outputs for real inputs #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-85f0dada3913>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                                         \u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtest_inds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mevent_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                         inf_times_as=inf_times_as, normalize=norm)\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mevent_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mevent_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/lfs3/user/jkager/NN_Reco/johannes/updownclassification_3/updown_network.py\u001b[0m in \u001b[0;36mgenerator\u001b[1;34m(batch_size, input_data, out_data, inds, inf_times_as, normalize)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mcur_event_id\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfill_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                 \u001b[0mtemp_in\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcur_file\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcur_event_id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mup_to\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 \u001b[0mtemp_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcur_file\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcur_event_id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mup_to\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                 \u001b[0mcur_len\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mup_to\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcur_event_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2840)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2798)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/jkager/.local/lib/python2.7/site-packages/h5py/_hl/dataset.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;31m# Perfom the actual read\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[0mmspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# choose the first n events that are correctly reconstructed\n",
    "n = 50\n",
    "event_mask = (np.round(res) == test_out)\n",
    "c=0\n",
    "for i, d in enumerate(event_mask):\n",
    "    if d: \n",
    "        c+=1\n",
    "    if c == n: \n",
    "        c = i\n",
    "        break\n",
    "event_mask[c+1:]=False\n",
    "gen = updown_network.generator(n, input_data, out_data, \n",
    "                                        [list(np.arange(*test_inds[0])[event_mask])],\n",
    "                                        inf_times_as=inf_times_as, normalize=norm)\n",
    "gen = list(gen)\n",
    "event_inputs = gen[0]\n",
    "event_outputs = gen[1]\n",
    "zeniths = zenith_out[event_mask]\n",
    "energies = out_data[0][list(np.arange(*test_inds[0])[event_mask]),\"energy\"]\n",
    "convlayer = filter(lambda f: 'conv' in f.name, model.layers)\n",
    "filter_outputs = [{f.name : np.zeros((f.filters)) for f in convlayer} \n",
    "                  for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function send>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 2 (64, 2)\n"
     ]
    }
   ],
   "source": [
    "print len(filter_outputs), len(filter_outputs[0]), filter_outputs[0].values()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 20, 10, 60)\n",
      "Processing event 0. Zenith: 2.23. Energy: 800280.411572\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Bad input argument to theano function with name \"/home/jkager/.local/lib/python2.7/site-packages/keras/backend/theano_backend.py:1191\" at index 0 (0-based).  \nBacktrace when that variable is created:\n\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/layers/__init__.py\", line 54, in deserialize\n    printable_module_name='layer')\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/utils/generic_utils.py\", line 140, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/models.py\", line 1217, in from_config\n    model.add(layer)\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/models.py\", line 439, in add\n    dtype=layer.dtype, name=layer.name + '_input')\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 1426, in Input\n    input_tensor=tensor)\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 1337, in __init__\n    name=self.name)\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 221, in placeholder\n    x = T.TensorType(dtype, broadcast)(name)\nWrong number of dimensions: expected 5, got 6 with shape (1, 50, 20, 10, 60, 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-b1731c72fbbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0minput_img_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_img_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimg_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_img_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mfilter_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfilter_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jkager/.local/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jkager/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    793\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[0;32m    794\u001b[0m                             \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jkager/.local/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[0;32m    176\u001b[0m             raise TypeError(\"Wrong number of dimensions: expected %s,\"\n\u001b[0;32m    177\u001b[0m                             \" got %s with shape %s.\" % (self.ndim, data.ndim,\n\u001b[1;32m--> 178\u001b[1;33m                                                         data.shape))\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maligned\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Bad input argument to theano function with name \"/home/jkager/.local/lib/python2.7/site-packages/keras/backend/theano_backend.py:1191\" at index 0 (0-based).  \nBacktrace when that variable is created:\n\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/layers/__init__.py\", line 54, in deserialize\n    printable_module_name='layer')\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/utils/generic_utils.py\", line 140, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/models.py\", line 1217, in from_config\n    model.add(layer)\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/models.py\", line 439, in add\n    dtype=layer.dtype, name=layer.name + '_input')\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 1426, in Input\n    input_tensor=tensor)\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/legacy/interfaces.py\", line 88, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/engine/topology.py\", line 1337, in __init__\n    name=self.name)\n  File \"/home/jkager/.local/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 221, in placeholder\n    x = T.TensorType(dtype, broadcast)(name)\nWrong number of dimensions: expected 5, got 6 with shape (1, 50, 20, 10, 60, 1)."
     ]
    }
   ],
   "source": [
    "absolute = False\n",
    "\n",
    "input_img=model.input\n",
    "i=-1\n",
    "for event in event_inputs:\n",
    "    i+=1\n",
    "    event = event[0]\n",
    "    img_shape = event.squeeze().shape\n",
    "    print img_shape\n",
    "    input_img_data = event\n",
    "    # we scan through every conv layer and every filter\n",
    "    print('Processing event {}. Zenith: {:.2f}. Energy: {}'.format(\n",
    "            i, zeniths[i], energies[i]))\n",
    "    \n",
    "    # we build a loss function that calculates the mean activation\n",
    "    # of the nth filter of the layer considered\n",
    "    for layer in convlayer:\n",
    "        layer_output = layer.output\n",
    "        for filter_index in range(n):\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                # (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)\n",
    "                act = K.mean(layer_output[:, filter_index, :, :, :])\n",
    "            else:\n",
    "                # (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)\n",
    "                act = K.mean(layer_output[:, :, :, :, filter_index])\n",
    "\n",
    "            if absolute:\n",
    "                act = K.abs(loss)\n",
    "\n",
    "            # this function returns the act value given the input picture\n",
    "            actval = K.function([input_img], [act])\n",
    "\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                input_img_data = input_img_data.reshape((1, 1)+img_shape)\n",
    "            else:\n",
    "                input_img_data = input_img_data.reshape((1,) + img_shape + (1,))\n",
    "\n",
    "            val = actval([input_img_data])\n",
    "\n",
    "            filter_outputs[i][layer.name][filter_index] = val\n",
    "\n",
    "#np.save(\"kept_{}{}_{}\".format(layer_name, \"_abs\" if absolute else \"\" , \"-\".join(project_folder.split(\"/\")[1:])),kept_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10, 60)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 10, 60, 1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_inputs[i].reshape(1,20,10,60,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
