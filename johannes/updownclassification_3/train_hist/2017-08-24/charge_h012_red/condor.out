
 ############################################
You are running the network script with arguments: 
virtual_len: -1
testing: False
filesizes: False
project: charge_h012_red
crtfolders: False
continue: None
using: charge
date: 2017-08-24
input: h012
model: CNN_red.cfg
############################################
 
[(0, 124352), (0, 125784), (0, 125878)]
[(124352, 165803), (125784, 167712), (125878, 167837)]
[(165803, 207253), (167712, 209639), (167837, 209796)]
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_1 (Conv3D)            (None, 9, 5, 28, 64)      3136      
_________________________________________________________________
batch_normalization_1 (Batch (None, 9, 5, 28, 64)      256       
_________________________________________________________________
activation_1 (Activation)    (None, 9, 5, 28, 64)      0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 80640)             0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 80640)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               10322048  
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 65        
=================================================================
Total params: 10,333,761
Trainable params: 10,333,633
Non-trainable params: 128
_________________________________________________________________
None
Epoch 1/30
Epoch 00000: val_loss improved from inf to 0.43509, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-24/charge_h012_red/best_val_loss.npy
RAM Usage 1.14 GB
814s - loss: 0.4622 - acc: 0.8183 - val_loss: 0.4351 - val_acc: 0.8258
Epoch 2/30
Epoch 00001: val_loss improved from 0.43509 to 0.43310, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-24/charge_h012_red/best_val_loss.npy
RAM Usage 1.14 GB
801s - loss: 0.4350 - acc: 0.8276 - val_loss: 0.4331 - val_acc: 0.8275
Epoch 3/30
Epoch 00002: val_loss improved from 0.43310 to 0.42782, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-24/charge_h012_red/best_val_loss.npy
RAM Usage 1.14 GB
801s - loss: 0.4265 - acc: 0.8309 - val_loss: 0.4278 - val_acc: 0.8300
Epoch 4/30
Epoch 00003: val_loss improved from 0.42782 to 0.42449, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-24/charge_h012_red/best_val_loss.npy
RAM Usage 1.14 GB
800s - loss: 0.4201 - acc: 0.8327 - val_loss: 0.4245 - val_acc: 0.8310
Epoch 5/30
Epoch 00004: val_loss improved from 0.42449 to 0.42352, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-24/charge_h012_red/best_val_loss.npy
RAM Usage 1.14 GB
799s - loss: 0.4164 - acc: 0.8345 - val_loss: 0.4235 - val_acc: 0.8316
Epoch 6/30
Epoch 00005: val_loss improved from 0.42352 to 0.42260, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-24/charge_h012_red/best_val_loss.npy
RAM Usage 1.14 GB
798s - loss: 0.4079 - acc: 0.8378 - val_loss: 0.4226 - val_acc: 0.8322
Epoch 7/30
Epoch 00006: val_loss improved from 0.42260 to 0.42002, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-24/charge_h012_red/best_val_loss.npy
RAM Usage 1.14 GB
800s - loss: 0.4033 - acc: 0.8393 - val_loss: 0.4200 - val_acc: 0.8339
Epoch 8/30
Epoch 00007: val_loss did not improve
RAM Usage 1.14 GB
798s - loss: 0.3986 - acc: 0.8409 - val_loss: 0.4210 - val_acc: 0.8325
Epoch 9/30
Epoch 00008: val_loss improved from 0.42002 to 0.41877, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-24/charge_h012_red/best_val_loss.npy
RAM Usage 1.14 GB
801s - loss: 0.3943 - acc: 0.8426 - val_loss: 0.4188 - val_acc: 0.8348
Epoch 10/30
Epoch 00009: val_loss did not improve
RAM Usage 1.14 GB
799s - loss: 0.3895 - acc: 0.8443 - val_loss: 0.4198 - val_acc: 0.8348
Epoch 11/30
Epoch 00010: val_loss improved from 0.41877 to 0.41104, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-24/charge_h012_red/best_val_loss.npy
RAM Usage 1.14 GB
801s - loss: 0.3851 - acc: 0.8463 - val_loss: 0.4110 - val_acc: 0.8388
Epoch 12/30
Epoch 00011: val_loss did not improve
RAM Usage 1.14 GB
800s - loss: 0.3810 - acc: 0.8481 - val_loss: 0.4114 - val_acc: 0.8391
Epoch 13/30
Epoch 00012: val_loss improved from 0.41104 to 0.40940, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-24/charge_h012_red/best_val_loss.npy
RAM Usage 1.14 GB
801s - loss: 0.3772 - acc: 0.8498 - val_loss: 0.4094 - val_acc: 0.8397
Epoch 14/30
Epoch 00013: val_loss improved from 0.40940 to 0.40657, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-24/charge_h012_red/best_val_loss.npy
RAM Usage 1.14 GB
805s - loss: 0.3739 - acc: 0.8510 - val_loss: 0.4066 - val_acc: 0.8405
Epoch 15/30
Epoch 00014: val_loss did not improve
RAM Usage 1.14 GB
805s - loss: 0.3711 - acc: 0.8522 - val_loss: 0.4079 - val_acc: 0.8398
Epoch 16/30
Epoch 00015: val_loss did not improve
RAM Usage 1.14 GB
802s - loss: 0.3657 - acc: 0.8539 - val_loss: 0.4094 - val_acc: 0.8397
Epoch 17/30
Epoch 00016: val_loss did not improve
RAM Usage 1.14 GB
799s - loss: 0.3627 - acc: 0.8549 - val_loss: 0.4172 - val_acc: 0.8386
Epoch 18/30
Epoch 00017: val_loss did not improve
RAM Usage 1.14 GB
800s - loss: 0.3585 - acc: 0.8568 - val_loss: 0.4127 - val_acc: 0.8404
Epoch 19/30
Epoch 00018: val_loss did not improve
RAM Usage 1.14 GB
799s - loss: 0.3545 - acc: 0.8582 - val_loss: 0.4222 - val_acc: 0.8404
Epoch 20/30
Epoch 00019: val_loss did not improve
RAM Usage 1.14 GB
806s - loss: 0.3525 - acc: 0.8592 - val_loss: 0.4234 - val_acc: 0.8382
Epoch 21/30
Epoch 00020: val_loss did not improve
RAM Usage 1.14 GB
804s - loss: 0.3493 - acc: 0.8603 - val_loss: 0.4186 - val_acc: 0.8395
Epoch 00020: early stopping
time to fit: 4h 41min 0.97sec

 Save the Model 


 Calculate Results... 

Predict Values for 11069_00000-00999.h5
Predict Values for 11069_01000-01999.h5
Predict Values for 11069_02000-02999.h5
105223 / 125336 =  83.95%
 
 Finished .... 
