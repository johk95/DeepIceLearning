
 ############################################
You are running the network script with arguments: 
virtual_len: -1
testing: False
filesizes: False
project: time_h012_v1_lowbatch
crtfolders: False
continue: None
using: time
date: 2017-08-28
input: h012
model: CNN_v1.cfg
############################################
 
[(0, 124352), (0, 125784), (0, 125878)]
[(124352, 165803), (125784, 167712), (125878, 167837)]
[(165803, 207253), (167712, 209639), (167837, 209796)]
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_1 (Conv3D)            (None, 9, 5, 28, 64)      3136      
_________________________________________________________________
batch_normalization_1 (Batch (None, 9, 5, 28, 64)      256       
_________________________________________________________________
activation_1 (Activation)    (None, 9, 5, 28, 64)      0         
_________________________________________________________________
conv3d_2 (Conv3D)            (None, 5, 3, 14, 64)      110656    
_________________________________________________________________
batch_normalization_2 (Batch (None, 5, 3, 14, 64)      256       
_________________________________________________________________
activation_2 (Activation)    (None, 5, 3, 14, 64)      0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 13440)             0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 13440)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               6881792   
_________________________________________________________________
dropout_2 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 256)               131328    
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 257       
=================================================================
Total params: 7,127,681
Trainable params: 7,127,425
Non-trainable params: 256
_________________________________________________________________
None
Epoch 1/30
Epoch 00000: val_loss improved from inf to 0.36433, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h012_v1_lowbatch/best_val_loss.npy
RAM Usage 0.90 GB
995s - loss: 0.4217 - acc: 0.8280 - val_loss: 0.3643 - val_acc: 0.8491
Epoch 2/30
Epoch 00001: val_loss improved from 0.36433 to 0.29642, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h012_v1_lowbatch/best_val_loss.npy
RAM Usage 0.90 GB
977s - loss: 0.3496 - acc: 0.8499 - val_loss: 0.2964 - val_acc: 0.8696
Epoch 3/30
Epoch 00002: val_loss improved from 0.29642 to 0.21939, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h012_v1_lowbatch/best_val_loss.npy
RAM Usage 0.90 GB
975s - loss: 0.2827 - acc: 0.8765 - val_loss: 0.2194 - val_acc: 0.9068
Epoch 4/30
Epoch 00003: val_loss improved from 0.21939 to 0.20328, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h012_v1_lowbatch/best_val_loss.npy
RAM Usage 0.90 GB
974s - loss: 0.2387 - acc: 0.8988 - val_loss: 0.2033 - val_acc: 0.9148
Epoch 5/30
Epoch 00004: val_loss improved from 0.20328 to 0.19316, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h012_v1_lowbatch/best_val_loss.npy
RAM Usage 0.90 GB
979s - loss: 0.2168 - acc: 0.9083 - val_loss: 0.1932 - val_acc: 0.9189
Epoch 6/30
Epoch 00005: val_loss improved from 0.19316 to 0.17796, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h012_v1_lowbatch/best_val_loss.npy
RAM Usage 0.90 GB
992s - loss: 0.2005 - acc: 0.9159 - val_loss: 0.1780 - val_acc: 0.9268
Epoch 7/30
Epoch 00006: val_loss improved from 0.17796 to 0.17476, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h012_v1_lowbatch/best_val_loss.npy
RAM Usage 0.90 GB
996s - loss: 0.1887 - acc: 0.9216 - val_loss: 0.1748 - val_acc: 0.9282
Epoch 8/30
Epoch 00007: val_loss did not improve
RAM Usage 0.90 GB
991s - loss: 0.1756 - acc: 0.9273 - val_loss: 0.1866 - val_acc: 0.9255
Epoch 9/30
Epoch 00008: val_loss improved from 0.17476 to 0.17282, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h012_v1_lowbatch/best_val_loss.npy
RAM Usage 0.90 GB
994s - loss: 0.1663 - acc: 0.9314 - val_loss: 0.1728 - val_acc: 0.9290
Epoch 10/30
Epoch 00009: val_loss did not improve
RAM Usage 0.90 GB
997s - loss: 0.1558 - acc: 0.9360 - val_loss: 0.1737 - val_acc: 0.9285
Epoch 11/30
Epoch 00010: val_loss did not improve
RAM Usage 0.90 GB
994s - loss: 0.1475 - acc: 0.9399 - val_loss: 0.1783 - val_acc: 0.9272
Epoch 12/30
Epoch 00011: val_loss did not improve
RAM Usage 0.90 GB
989s - loss: 0.1367 - acc: 0.9440 - val_loss: 0.1844 - val_acc: 0.9283
Epoch 13/30
Epoch 00012: val_loss did not improve
RAM Usage 0.90 GB
985s - loss: 0.1294 - acc: 0.9473 - val_loss: 0.1831 - val_acc: 0.9290
Epoch 14/30
Epoch 00013: val_loss did not improve
RAM Usage 0.90 GB
997s - loss: 0.1218 - acc: 0.9506 - val_loss: 0.1802 - val_acc: 0.9286
Epoch 15/30
Epoch 00014: val_loss did not improve
RAM Usage 0.90 GB
990s - loss: 0.1164 - acc: 0.9535 - val_loss: 0.1821 - val_acc: 0.9297
Epoch 16/30
Epoch 00015: val_loss did not improve
RAM Usage 0.90 GB
978s - loss: 0.1102 - acc: 0.9561 - val_loss: 0.1939 - val_acc: 0.9260
Epoch 00015: early stopping
time to fit: 4h 23min 46.30sec

 Save the Model 


 Calculate Results... 

Predict Values for 11069_00000-00999.h5
Predict Values for 11069_01000-01999.h5
Predict Values for 11069_02000-02999.h5
115968 / 125336 =  92.53%
 
 Finished .... 
