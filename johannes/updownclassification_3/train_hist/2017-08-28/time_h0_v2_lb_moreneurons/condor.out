
 ############################################
You are running the network script with arguments: 
virtual_len: -1
testing: False
filesizes: False
project: time_h0_v2_lb_moreneurons
crtfolders: False
continue: None
using: time
date: 2017-08-28
input: h0
model: CNN_v2.cfg
############################################
 
[(0, 124352)]
[(124352, 165803)]
[(165803, 207253)]
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv3d_1 (Conv3D)            (None, 10, 10, 20, 64)    3136      
_________________________________________________________________
batch_normalization_1 (Batch (None, 10, 10, 20, 64)    256       
_________________________________________________________________
activation_1 (Activation)    (None, 10, 10, 20, 64)    0         
_________________________________________________________________
conv3d_2 (Conv3D)            (None, 10, 10, 10, 32)    55328     
_________________________________________________________________
batch_normalization_2 (Batch (None, 10, 10, 10, 32)    128       
_________________________________________________________________
activation_2 (Activation)    (None, 10, 10, 10, 32)    0         
_________________________________________________________________
max_pooling3d_1 (MaxPooling3 (None, 5, 5, 5, 32)       0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 4000)              0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 4000)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               2048512   
_________________________________________________________________
dropout_2 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 256)               131328    
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 257       
=================================================================
Total params: 2,238,945
Trainable params: 2,238,753
Non-trainable params: 192
_________________________________________________________________
None
Epoch 1/30
Epoch 00000: val_loss improved from inf to 0.42068, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h0_v2_lb_moreneurons/best_val_loss.npy
RAM Usage 0.81 GB
525s - loss: 0.4770 - acc: 0.8029 - val_loss: 0.4207 - val_acc: 0.8286
Epoch 2/30
Epoch 00001: val_loss improved from 0.42068 to 0.39648, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h0_v2_lb_moreneurons/best_val_loss.npy
RAM Usage 0.81 GB
528s - loss: 0.4160 - acc: 0.8290 - val_loss: 0.3965 - val_acc: 0.8344
Epoch 3/30
Epoch 00002: val_loss improved from 0.39648 to 0.36528, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h0_v2_lb_moreneurons/best_val_loss.npy
RAM Usage 0.81 GB
526s - loss: 0.3939 - acc: 0.8359 - val_loss: 0.3653 - val_acc: 0.8467
Epoch 4/30
Epoch 00003: val_loss improved from 0.36528 to 0.35587, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h0_v2_lb_moreneurons/best_val_loss.npy
RAM Usage 0.81 GB
525s - loss: 0.3778 - acc: 0.8410 - val_loss: 0.3559 - val_acc: 0.8479
Epoch 5/30
Epoch 00004: val_loss improved from 0.35587 to 0.34382, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h0_v2_lb_moreneurons/best_val_loss.npy
RAM Usage 0.81 GB
526s - loss: 0.3629 - acc: 0.8452 - val_loss: 0.3438 - val_acc: 0.8525
Epoch 6/30
Epoch 00005: val_loss improved from 0.34382 to 0.31674, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h0_v2_lb_moreneurons/best_val_loss.npy
RAM Usage 0.81 GB
525s - loss: 0.3453 - acc: 0.8504 - val_loss: 0.3167 - val_acc: 0.8594
Epoch 7/30
Epoch 00006: val_loss improved from 0.31674 to 0.29010, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h0_v2_lb_moreneurons/best_val_loss.npy
RAM Usage 0.81 GB
527s - loss: 0.3252 - acc: 0.8594 - val_loss: 0.2901 - val_acc: 0.8694
Epoch 8/30
Epoch 00007: val_loss improved from 0.29010 to 0.27460, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h0_v2_lb_moreneurons/best_val_loss.npy
RAM Usage 0.81 GB
526s - loss: 0.3026 - acc: 0.8677 - val_loss: 0.2746 - val_acc: 0.8831
Epoch 9/30
Epoch 00008: val_loss improved from 0.27460 to 0.25295, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h0_v2_lb_moreneurons/best_val_loss.npy
RAM Usage 0.81 GB
526s - loss: 0.2810 - acc: 0.8781 - val_loss: 0.2529 - val_acc: 0.8933
Epoch 10/30
Epoch 00009: val_loss improved from 0.25295 to 0.24481, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h0_v2_lb_moreneurons/best_val_loss.npy
RAM Usage 0.81 GB
527s - loss: 0.2609 - acc: 0.8863 - val_loss: 0.2448 - val_acc: 0.8988
Epoch 11/30
Epoch 00010: val_loss improved from 0.24481 to 0.22652, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h0_v2_lb_moreneurons/best_val_loss.npy
RAM Usage 0.81 GB
526s - loss: 0.2470 - acc: 0.8935 - val_loss: 0.2265 - val_acc: 0.9069
Epoch 12/30
Epoch 00011: val_loss did not improve
RAM Usage 0.81 GB
526s - loss: 0.2327 - acc: 0.9003 - val_loss: 0.2537 - val_acc: 0.9036
Epoch 13/30
Epoch 00012: val_loss did not improve
RAM Usage 0.81 GB
527s - loss: 0.2212 - acc: 0.9051 - val_loss: 0.2831 - val_acc: 0.8963
Epoch 14/30
Epoch 00013: val_loss improved from 0.22652 to 0.21657, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h0_v2_lb_moreneurons/best_val_loss.npy
RAM Usage 0.81 GB
526s - loss: 0.2114 - acc: 0.9093 - val_loss: 0.2166 - val_acc: 0.9127
Epoch 15/30
Epoch 00014: val_loss improved from 0.21657 to 0.21400, saving model to /data/user/jkager/NN_Reco/johannes/updownclassification_3/train_hist/2017-08-28/time_h0_v2_lb_moreneurons/best_val_loss.npy
RAM Usage 0.81 GB
527s - loss: 0.2044 - acc: 0.9123 - val_loss: 0.2140 - val_acc: 0.9128
Epoch 16/30
Epoch 00015: val_loss did not improve
RAM Usage 0.81 GB
527s - loss: 0.1903 - acc: 0.9187 - val_loss: 0.2188 - val_acc: 0.9114
Epoch 17/30
Epoch 00016: val_loss did not improve
RAM Usage 0.81 GB
526s - loss: 0.1824 - acc: 0.9224 - val_loss: 0.2311 - val_acc: 0.9128
Epoch 18/30
Epoch 00017: val_loss did not improve
RAM Usage 0.81 GB
527s - loss: 0.1747 - acc: 0.9261 - val_loss: 0.2226 - val_acc: 0.9119
Epoch 19/30
Epoch 00018: val_loss did not improve
RAM Usage 0.81 GB
527s - loss: 0.1668 - acc: 0.9298 - val_loss: 0.2171 - val_acc: 0.9139
Epoch 20/30
Epoch 00019: val_loss did not improve
RAM Usage 0.81 GB
526s - loss: 0.1597 - acc: 0.9325 - val_loss: 0.2291 - val_acc: 0.9114
Epoch 21/30
Epoch 00020: val_loss did not improve
RAM Usage 0.81 GB
526s - loss: 0.1522 - acc: 0.9362 - val_loss: 0.2192 - val_acc: 0.9146
Epoch 22/30
Epoch 00021: val_loss did not improve
RAM Usage 0.81 GB
528s - loss: 0.1440 - acc: 0.9404 - val_loss: 0.2318 - val_acc: 0.9135
Epoch 00021: early stopping
time to fit: 3h 13min 34.24sec

 Save the Model 


 Calculate Results... 

Predict Values for 11069_00000-00999.h5
37807 / 41450 =  91.21%
 
 Finished .... 
